{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccdb8349",
   "metadata": {},
   "source": [
    "# STA130 Homework 06\n",
    "\n",
    "Please see the course [wiki-textbook](https://github.com/pointOfive/stat130chat130/wiki) for the list of topics covered in this homework assignment, and a list of topics that might appear during ChatBot conversations which are \"out of scope\" for the purposes of this homework assignment (and hence can be safely ignored if encountered)\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Introduction</u></summary>\n",
    "\n",
    "### Introduction\n",
    "    \n",
    "A reasonable characterization of STA130 Homework is that it simply defines a weekly reading comprehension assignment. \n",
    "Indeed, STA130 Homework essentially boils down to completing various understanding confirmation exercises oriented around coding and writing tasks.\n",
    "However, rather than reading a textbook, STA130 Homework is based on ChatBots so students can interactively follow up to clarify questions or confusion that they may still have regarding learning objective assignments.\n",
    "\n",
    "> Communication is a fundamental skill underlying statistics and data science, so STA130 Homework based on ChatBots helps practice effective two-way communication as part of a \"realistic\" dialogue activity supporting underlying conceptual understanding building. \n",
    "\n",
    "It will likely become increasingly tempting to rely on ChatBots to \"do the work for you\". But when you find yourself frustrated with a ChatBots inability to give you the results you're looking for, this is a \"hint\" that you've become overreliant on the ChatBots. Your objective should not be to have ChatBots \"do the work for you\", but to use ChatBots to help you build your understanding so you can efficiently leverage ChatBots (and other resources) to help you work more efficiently.<br><br>\n",
    "\n",
    "</details>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Instructions</u></summary>\n",
    "\n",
    "### Instructions\n",
    "    \n",
    "1. Code and write all your answers (for both the \"Pre-lecture\" and \"Post-lecture\" HW) in a python notebook (in code and markdown cells) \n",
    "    \n",
    "> It is *suggested but not mandatory* that you complete the \"Pre-lecture\" HW prior to the Monday LEC since (a) all HW is due at the same time; but, (b) completing some of the HW early will mean better readiness for LEC and less of a \"procrastentation cruch\" towards the end of the week...\n",
    "    \n",
    "2. Paste summaries of your ChatBot sessions (including link(s) to chat log histories if you're using ChatGPT) within your notebook\n",
    "    \n",
    "> Create summaries of your ChatBot sessions by using concluding prompts such as \"Please provide a summary of our exchanges here so I can submit them as a record of our interactions as part of a homework assignment\" or, \"Please provide me with the final working verson of the code that we created together\"\n",
    "    \n",
    "3. Save your python jupyter notebook in your own account and \"repo\" on [github.com](github.com) and submit a link to that notebook though Quercus for assignment marking<br><br>\n",
    "\n",
    "</details>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Prompt Engineering?</u></summary>\n",
    "    \n",
    "### Prompt Engineering? \n",
    "    \n",
    "The questions (as copy-pasted prompts) are designed to initialize appropriate ChatBot conversations which can be explored in the manner of an interactive and dynamic textbook; but, it is nonetheless **strongly recommendated** that your rephrase the questions in a way that you find natural to ensure a clear understanding of the question. Given sensible prompts the represent a question well, the two primary challenges observed to arise from ChatBots are \n",
    "\n",
    "1. conversations going beyond the intended scope of the material addressed by the question; and, \n",
    "2. unrecoverable confusion as a result of sequential layers logial inquiry that cannot be resolved. \n",
    "\n",
    "In the case of the former (1), adding constraints specifying the limits of considerations of interest tends to be helpful; whereas, the latter (2) is often the result of initial prompting that leads to poor developments in navigating the material, which are likely just best resolve by a \"hard reset\" with a new initial approach to prompting.  Indeed, this is exactly the behavior [hardcoded into copilot](https://answers.microsoft.com/en-us/bing/forum/all/is-this-even-normal/0b6dcab3-7d6c-4373-8efe-d74158af3c00)...\n",
    "\n",
    "</details>\n",
    "\n",
    "### Marking Rubric (which may award partial credit) \n",
    "\n",
    "- [0.1 points]: All relevant ChatBot summaries [including link(s) to chat log histories if you're using ChatGPT] are reported within the notebook\n",
    "- [0.2 points]: Evaluation of correctness and clarity in written communication for Question \"3\"\n",
    "- [0.2 points]: Evaluation of correctness and clarity in written communication for Question \"4\"\n",
    "- [0.2 points]: Evaluation of submitted work and conclusions for Question \"9\"\n",
    "- [0.3 points]: Evaluation of written communication of the \"big picture\" differences and correct evidence assessement for Question \"11\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d53fb",
   "metadata": {},
   "source": [
    "## \"Pre-lecture\" versus \"Post-lecture\" HW? \n",
    "\n",
    "- _**Your HW submission is due prior to the Nov08 TUT on Friday after you return from Reading Week; however,**_\n",
    "- _**this homework assignment is longer since it covers material from both the Oct21 and Nov04 LEC (rather than a single LEC); so,**_\n",
    "- _**we'll brake the assignment into \"Week of Oct21\" and \"Week of Nov04\" HW and/but ALL of it will be DUE prior to the Nov08 TUT**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bd5e04",
   "metadata": {},
   "source": [
    "## \"Week of Oct21\" HW [*due prior to the Nov08 TUT*]\n",
    "\n",
    "### 1. Explain the theoretical Simple Linear Regression model in your own words by describing its components (of predictor and outcome variables, slope and intercept coefficients, and an error term) and how they combine to form a sample from normal distribution; then, create *python* code explicitly demonstrating your explanation using *numpy* and *scipy.stats* <br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _Your answer can be quite concise and will likely just address the \"mathematical\" and \"statistical\" aspects of the process of a **Simple Linear Model** specification, perhaps giving an intuitive interpretation summary of the result as a whole_\n",
    ">   \n",
    "> - _Your code could be based on values for `n`, `x`, `beta0`, `beta1`, and `sigma`; and, then create the `errors` and `Y`_\n",
    "> \n",
    "> - _The predictors $x_i$ can be fixed arbitrarily to start the process (perhaps sampled using `stats.uniform`), and they are conceptually different from the creation of **error** (or **noise**) terms $\\epsilon_i$ which are sampled from a **normal distribution** (with some aribtrarily *a priori* chosen **standard deviation** `scale` parameter $\\sigma$) which are then combined with $x_i$ through the **Simple Linear Model** equation (based on aribtrarily *a priori* chosen **slope** and **intercept coefficients**) to produce the $Y_i$ outcomes_\n",
    "> \n",
    "> - _It should be fairly easy to visualize the \"a + bx\" line defined by the **Simple Linear Model** equation, and some **simulated** data points around the line in a `plotly` figure using the help of a ChatBot_\n",
    "> \n",
    "> _If you use a ChatBot (as expected for this problem), **don't forget to ask for summaries of your ChatBot session(s) and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatGPT)**_\n",
    ">\n",
    "> \n",
    "> _**Question Scope Warning:** Be careful when using a ChatBot to help you with creating an example dataset and coding up a visualization though, **because it might suggest creating (and visualizing) a fitted model for to your data (rather than the theoretical model); but, this is not what this question is asking you to demonstrate**. This question is not asking about how to produce a fitted **Simple Linear Regression** model or explain how model **slope** and **intercept coefficients** are calculated (e.g., using \"ordinary least squares\" or analytical equations to estimate the **coefficients**  for an observed dataset)._\n",
    "> \n",
    "> ```python\n",
    "> # There are two distinct ways to use `plotly` here\n",
    ">\n",
    "> import plotly.express as px\n",
    "> px.scatter(df, x='x',  y='Y', color='Data', \n",
    ">            trendline='ols', title='Y vs. x')\n",
    ">        \n",
    "> import plotly.graph_objects as go\n",
    "> fig = go.Figure()\n",
    "> fig.add_trace(go.Scatter(x=x, y=Y, mode='markers', name='Data'))\n",
    "> \n",
    "> # The latter is preferable since `trendline='ols'` in the former \n",
    "> # creates a fitted model for the data and adds it to the figure\n",
    "> # and, again, THAT IS NOT what this problem is asking for right now\n",
    "> ```\n",
    ">    \n",
    "> ---\n",
    "> \n",
    "> _Don't forget to ask for summaries of all your different ChatBot sessions and organize and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatBot) But if you're using the STA130 custom NBLM ChatBot, you'll only be able to ask for summaries, of course!_  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2889e8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A theoretical simple linear regression model is a basic \n",
    "statistical tool used to describe the relationship between\n",
    "two variables.\n",
    "The regression equation:\n",
    "Y = beta0 + beta1 X + errors\n",
    "Y is the outcome variable(dependent variable)\n",
    "X is the predictor variable(independent variable)\n",
    "beta0 is the intercept of the line\n",
    "beta1 is the slope of the line\n",
    "error is the error term, representing the random deviation\n",
    "of each observation from the expected line\n",
    "\n",
    "In a standard linear regression model, error term is normally\n",
    "distributed:\n",
    "ϵ∼N(0,σ^2)\n",
    "combine those components to from a normal distribution for Y\n",
    "Y∼N(beta0 + beta1 X, sigma ^2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9159c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import uniform, norm\n",
    "\n",
    "# Set parameters\n",
    "n = 50  # Number of data points\n",
    "beta0 = 2  # Intercept\n",
    "beta1 = 1.5  # Slope\n",
    "sigma = 0.5  # Standard deviation of error term\n",
    "\n",
    "# Generate predictors (x) and errors\n",
    "x = uniform.rvs(0, 10, size=n)\n",
    "errors = norm.rvs(0, sigma, size=n)\n",
    "Y = beta0 + beta1 * x + errors\n",
    "\n",
    "# Create figure with plotly.graph_objects (no fitted trendline)\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add data points\n",
    "fig.add_trace(go.Scatter(x=x, y=Y, mode='markers', name='Simulated Data'))\n",
    "\n",
    "# Add theoretical regression line\n",
    "x_line = np.linspace(min(x), max(x), 100)\n",
    "y_line = beta0 + beta1 * x_line\n",
    "fig.add_trace(go.Scatter(x=x_line, y=y_line, mode='lines', name='SLM Line (Y = β0 + β1x)', line=dict(color='blue')))\n",
    "\n",
    "# Customize plot\n",
    "fig.update_layout(title=\"Simple Linear Model Specification without Fitting\",\n",
    "                  xaxis_title=\"x (Predictor)\", yaxis_title=\"Y (Outcome)\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b9cf2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "chatgpt link: https://chatgpt.com/share/672d5997-8c68-8008-aef3-c8b21a9e0a5a\n",
    "\n",
    "### Simple Linear Model (SLM) Specification with Python and Plotly\n",
    "\n",
    "This section demonstrates the theoretical setup of a Simple Linear Model (SLM) using Python. \n",
    "The SLM equation \\( Y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i \\) was specified with:\n",
    "- **Fixed intercept (\\( \\beta_0 \\))**, **slope (\\( \\beta_1 \\))**, and **error term standard deviation (\\( \\sigma \\))**.\n",
    "- **Predictors** \\( x_i \\) generated from a uniform distribution.\n",
    "- **Error terms** \\( \\epsilon_i \\) sampled from a normal distribution with mean 0 and standard deviation \\( \\sigma \\).\n",
    "\n",
    "Using these components, \\( Y \\) values were calculated by combining \\( x \\) values, slope, intercept, and errors. \n",
    "The theoretical regression line \\( Y = \\beta_0 + \\beta_1 x \\) was plotted alongside simulated data points to illustrate the expected distribution of \\( Y \\) around the line.\n",
    "\n",
    "**Visualization**:  \n",
    "To avoid fitting a model, we used `plotly.graph_objects` instead of `plotly.express`, which would otherwise add a trendline. \n",
    "The `graph_objects` approach allowed us to show only the theoretical line and data points, as the question requested.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48944c8d",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0966465a",
   "metadata": {},
   "source": [
    "### 2. Use a dataset simulated from your theoretical Simple Linear Regression model to demonstrate how to create and visualize a fitted Simple Linear Regression model using *pandas* and *import statsmodels.formula.api as smf*<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> - _Combine the **simulated** `x` and `Y` into a `pandas` data frame object named `df` with the column names \"x\" and \"Y\"_\n",
    "> \n",
    "> - _Replace the inline question comments below with their answers (working with a ChatBot if needed)_\n",
    ">\n",
    "> ```python\n",
    "> import statsmodels.formula.api as smf  # what is this library for?\n",
    "> import plotly.express as px  # this is a ploting library\n",
    ">\n",
    "> # what are the following two steps doing?\n",
    "> model_data_specification = smf.ols(\"Y~x\", data=df) \n",
    "> fitted_model = model_data_specification.fit() \n",
    ">\n",
    "> # what do each of the following provide?\n",
    "> fitted_model.summary()  # simple explanation? \n",
    "> fitted_model.summary().tables[1]  # simple explanation?\n",
    "> fitted_model.params  # simple explanation?\n",
    "> fitted_model.params.values  # simple explanation?\n",
    "> fitted_model.rsquared  # simple explanation?\n",
    ">\n",
    "> # what two things does this add onto the figure?\n",
    "> df['Data'] = 'Data' # hack to add data to legend \n",
    "> fig = px.scatter(df, x='x',  y='Y', color='Data', \n",
    ">                  trendline='ols', title='Y vs. x')\n",
    ">\n",
    "> # This is essentially what above `trendline='ols'` does\n",
    "> fig.add_scatter(x=df['x'], y=fitted_model.fittedvalues,\n",
    ">                 line=dict(color='blue'), name=\"trendline='ols'\")\n",
    "> \n",
    "> fig.show() # USE `fig.show(renderer=\"png\")` FOR ALL GitHub and MarkUs SUBMISSIONS\n",
    "> ```\n",
    ">\n",
    "> _The plotting here uses the `plotly.express` form `fig.add_scatter(x=x, y=Y)` rather than the `plotly.graph_objects` form `fig.add_trace(go.Scatter(x=x, y=Y))`. The difference between these two was noted in the \"Further Guidance\" comments in the previous question; but, the preference for the former in this case is because `px` allows us to access `trendline='ols'` through `px.scatter(df, x='x',  y='Y', trendline='ols')`_\n",
    ">\n",
    "> ---\n",
    "> \n",
    "> _Don't forget to ask for summaries of all your different ChatBot sessions and organize and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatBot) But if you're using the STA130 custom NBLM ChatBot, you'll only be able to ask for summaries, of course!_      \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96e09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question 2\n",
    "summary:\n",
    "Simulated a Dataset: Defined an arbitrary intercept, slope, and random error to generate predictor (X) and response (Y) values.\n",
    "Fitted the Model: Used statsmodels.formula.api with smf.ols to fit the linear regression model.\n",
    "Visualized the Results: Created a scatter plot of the observed data with the fitted regression line, using Matplotlib.\n",
    "Interpreted Model Summary: Outputted a summary of the fitted model, which includes important statistical metrics.\n",
    "This process demonstrated both the practical visualization and statistical analysis of a simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26254513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Step 1: Simulate the Dataset\n",
    "np.random.seed(0)  # For reproducibility\n",
    "n = 100  # Number of observations\n",
    "\n",
    "# Define parameters for the theoretical linear model\n",
    "intercept = 5\n",
    "slope = 2\n",
    "error_std = 1  # Standard deviation of the random error\n",
    "\n",
    "# Generate predictor (X) values\n",
    "X = np.random.uniform(0, 10, n)\n",
    "\n",
    "# Calculate response (Y) values based on the linear model, adding random error\n",
    "error = np.random.normal(0, error_std, n)\n",
    "Y = intercept + slope * X + error\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'X': X, 'Y': Y})\n",
    "\n",
    "# Step 2: Fit the Linear Model with statsmodels\n",
    "model = smf.ols('Y ~ X', data=data).fit()\n",
    "\n",
    "# Step 3: Visualize the Results\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot of the data\n",
    "plt.scatter(data['X'], data['Y'], color='blue', alpha=0.5, label='Observed Data')\n",
    "\n",
    "# Plot the fitted regression line\n",
    "X_pred = np.linspace(0, 10, 100)  # X values for prediction\n",
    "Y_pred = model.predict(pd.DataFrame({'X': X_pred}))  # Predicted Y values\n",
    "plt.plot(X_pred, Y_pred, color='red', label='Fitted Regression Line')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Simple Linear Regression: Observed Data and Fitted Line')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Display model summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b74dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt link: https://chatgpt.com/share/672d5997-8c68-8008-aef3-c8b21a9e0a5a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9441b1ab",
   "metadata": {},
   "source": [
    "### 3. Add the line from Question 1 on the figure of Question 2 and explain the difference between the nature of the two lines in your own words; *but, hint though: simulation of random sampling variation*<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _This question is effectively asking you to explain what the combined code you produced for Questions 1 and 2 is trying to demonstrate overall. If you're working with a ChatBot (as expected), giving these two sets of code as context, and asking what the purpose of comparing these lines could be would be a way to get some help in formulating your answer_\n",
    "> \n",
    "> _The graphical visualization aspect of this question could be accomplished by appending the following code to the code provided in Question 2._\n",
    "> \n",
    "> ```python\n",
    "> # what does this add onto the figure in constrast to `trendline='ols'`?\n",
    "> x_range = np.array([df['x'].min(), df['x'].max()])\n",
    "> # beta0 and beta1 are assumed to be defined\n",
    "> y_line = beta0 + beta1 * x_range\n",
    "> fig.add_scatter(x=x_range, y=y_line, mode='lines',\n",
    ">                 name=str(beta0)+' + '+str(beta1)+' * x', \n",
    ">                 line=dict(dash='dot', color='orange'))\n",
    ">\n",
    "> fig.show() # USE `fig.show(renderer=\"png\")` FOR ALL GitHub and MarkUs SUBMISSIONS\n",
    "> ```\n",
    "> \n",
    "> _The right way to interactively \"see\" the answer to this question is to repeatedly create different dataset **simulations** using your theoretical model and the corresponding fitted models, and repeatedly visualize the data and the two lines over and over... this would be as easy as rerunning a single cell containing your simulation and visualization code..._\n",
    ">    \n",
    "> ---\n",
    "> \n",
    "> _Don't forget to ask for summaries of all your different ChatBot sessions and organize and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatBot) But if you're using the STA130 custom NBLM ChatBot, you'll only be able to ask for summaries, of course!_  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c82d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "question3\n",
    "summary:\n",
    "\n",
    "### Comparison of Theoretical and Fitted Simple Linear Regression Lines\n",
    "\n",
    "Using a simulated dataset, we created two lines on the same plot:\n",
    "1. **Theoretical Line** (dashed blue): Represents the true relationship \\( Y = \\beta_0 + \\beta_1 x \\) \n",
    "as specified by our chosen slope and intercept, without any random variation.\n",
    "2. **Fitted Line** (solid red): Estimated using `statsmodels` from the simulated data, which includes \n",
    "random errors. Due to **random sampling variation** in each sample, this line may differ slightly from the theoretical line.\n",
    "\n",
    "This visualization illustrates how random sampling affects the fitted model, leading to small differences \n",
    "from the true model even when we know the \"true\" parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692986ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import uniform, norm\n",
    "\n",
    "# Parameters for data simulation\n",
    "n = 50\n",
    "beta0 = 2  # Theoretical Intercept\n",
    "beta1 = 1.5  # Theoretical Slope\n",
    "sigma = 0.5  # Standard deviation of error term\n",
    "\n",
    "# Generate predictors and errors\n",
    "np.random.seed(42)\n",
    "x = uniform.rvs(0, 10, size=n)\n",
    "errors = norm.rvs(0, sigma, size=n)\n",
    "Y = beta0 + beta1 * x + errors  # Simulated response variable\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'x': x, 'Y': Y})\n",
    "\n",
    "# Fit a Simple Linear Regression model\n",
    "model = smf.ols('Y ~ x', data=df).fit()\n",
    "\n",
    "# Visualization\n",
    "fig = go.Figure()\n",
    "\n",
    "# Plot the simulated data points\n",
    "fig.add_trace(go.Scatter(x=df['x'], y=df['Y'], mode='markers', name='Simulated Data'))\n",
    "\n",
    "# Plot the theoretical regression line (Question 1)\n",
    "x_line = np.linspace(min(x), max(x), 100)\n",
    "y_theoretical = beta0 + beta1 * x_line\n",
    "fig.add_trace(go.Scatter(x=x_line, y=y_theoretical, mode='lines', name='Theoretical Line', line=dict(color='blue', dash='dash')))\n",
    "\n",
    "# Plot the fitted regression line (Question 2)\n",
    "y_fitted = model.params['Intercept'] + model.params['x'] * x_line\n",
    "fig.add_trace(go.Scatter(x=x_line, y=y_fitted, mode='lines', name='Fitted Line', line=dict(color='red')))\n",
    "\n",
    "# Customize plot\n",
    "fig.update_layout(title=\"Theoretical vs. Fitted Simple Linear Regression Lines\",\n",
    "                  xaxis_title=\"x (Predictor)\", yaxis_title=\"Y (Outcome)\")\n",
    "fig.show(renderer=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf2203",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt link: https://chatgpt.com/share/672d5997-8c68-8008-aef3-c8b21a9e0a5a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b9c1c7",
   "metadata": {},
   "source": [
    "### 4. Explain how *fitted_model.fittedvalues* are derived on the basis of *fitted_model.summary().tables[1]* (or more specifically  *fitted_model.params* or *fitted_model.params.values*)<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _The previous questions used code to explore the distinction between theoretical (true) $Y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i \\;[\\text{where } \\epsilon_i \\sim \\mathcal{N}(0, \\sigma)]\\;$ and fitted (estimated) $\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i$ **Simple Linear Regression** models_\n",
    ">\n",
    "> _This question asks you to explicitly illustrate how the the latter \"in sample predictions\" of the fitted **Simple Linear Regression** model $\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i$ are made (in contrast to the linear equation of the theoretical model)_\n",
    ">    \n",
    "> ---\n",
    "> \n",
    "> _Don't forget to ask for summaries of all your different ChatBot sessions and organize and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatBot) But if you're using the STA130 custom NBLM ChatBot, you'll only be able to ask for summaries, of course!_  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ef9e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "The `fitted_model.fittedvalues` in a regression model represent \n",
    "the predicted \\( Y \\)-values for each observation in the dataset,\n",
    "calculated using the estimated coefficients (parameters) found in \n",
    "`fitted_model.params`. Here’s how they’re derived from `fitted_model.params` \n",
    "and shown in `fitted_model.summary().tables[1]`:\n",
    "\n",
    "1. **Coefficients Estimation**:  \n",
    "   In the summary table (`fitted_model.summary().tables[1]`), \n",
    "you’ll find the estimated intercept and slope coefficients under `coef`. \n",
    "These values are also stored in `fitted_model.params`, with:\n",
    "   - `fitted_model.params['Intercept']` representing the intercept \n",
    "(\\( \\hat{\\beta}_0 \\))\n",
    "   - `fitted_model.params['x']` representing the slope \n",
    "    (\\( \\hat{\\beta}_1 \\))\n",
    "\n",
    "2. **Fitted Values Calculation**:  \n",
    "   Using these estimated coefficients, the fitted (predicted) \n",
    "values for each \\( Y \\)-value are calculated by:\n",
    "   \\[\n",
    "   \\text{fitted value}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i\n",
    "   \\]\n",
    "   where \\( x_i \\) is the predictor value for observation \\( i \\).\n",
    "\n",
    "3. **Accessing Fitted Values**:  \n",
    "   `fitted_model.fittedvalues` provides the result of this calculation \n",
    "across all observations, giving the model’s predictions based on the \n",
    "estimated coefficients.\n",
    "\n",
    "### Summary\n",
    "In essence, `fitted_model.fittedvalues` are derived by plugging\n",
    "each \\( x_i \\) into the regression equation using the intercept and \n",
    "slope estimates found in `fitted_model.params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e610e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt link: https://chatgpt.com/share/672d5997-8c68-8008-aef3-c8b21a9e0a5a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd86910",
   "metadata": {},
   "source": [
    "### 5. Explain concisely in your own words what line is chosen for the fitted model based on observed data using the \"ordinary least squares\" method (as is done by *trendline='ols'* and *smf.ols(...).fit()*) and why it requires \"squares\"<br>\n",
    "    \n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _This question addresses the use of **residuals** $\\text{e}_i = \\hat \\epsilon_i = Y_i - \\hat y_i$ (in contrast to the **error** terms $\\epsilon_i$ of the theoretical model), and particularly, asks for an explanation based on the following visualization_\n",
    ">\n",
    "> ```python \n",
    "> import scipy.stats as stats\n",
    "> import numpy as np\n",
    "> import pandas as pd\n",
    "> import statsmodels.formula.api as smf\n",
    "> import plotly.express as px\n",
    "> \n",
    "> n,x_min,x_range,beta0,beta1,sigma = 20,5,5,2,3,5\n",
    "> x = stats.uniform(x_min, x_range).rvs(size=n)\n",
    "> errors = stats.norm(loc=0, scale=sigma).rvs(size=n)\n",
    "> Y = beta0 + beta1 * x + errors\n",
    "> \n",
    "> df = pd.DataFrame({'x': x, 'y': Y})\n",
    "> model_data_specification = smf.ols(\"Y~x\", data=df) \n",
    "> fitted_model = model_data_specification.fit() \n",
    "> \n",
    "> df['Data'] = 'Data' # hack to add data to legend \n",
    "> fig = px.scatter(df, x='x',  y='Y', color='Data', \n",
    ">                  trendline='ols', title='Y vs. x')\n",
    "> \n",
    "> # This is what `trendline='ols'` is\n",
    "> fig.add_scatter(x=df['x'], y=fitted_model.fittedvalues,\n",
    ">                 line=dict(color='blue'), name=\"trendline='ols'\")\n",
    "> \n",
    "> x_range = np.array([df['x'].min(), df['x'].max()])\n",
    "> y_line = beta0 + beta1 * x_range\n",
    "> fig.add_scatter(x=x_range, y=y_line, mode='lines',\n",
    ">                 name=str(beta0)+' + '+str(beta1)+' * x', \n",
    ">                 line=dict(dash='dot', color='orange'))\n",
    "> \n",
    "> # Add vertical lines for residuals\n",
    "> for i in range(len(df)):\n",
    ">     fig.add_scatter(x=[df['x'][i], df['x'][i]],\n",
    ">                     y=[fitted_model.fittedvalues[i], df['Y'][i]],\n",
    ">                     mode='lines',\n",
    ">                     line=dict(color='red', dash='dash'),\n",
    ">                     showlegend=False)\n",
    ">     \n",
    "> # Add horizontal line at y-bar\n",
    "> fig.add_scatter(x=x_range, y=[df['Y'].mean()]*2, mode='lines',\n",
    ">                 line=dict(color='black', dash='dot'), name='y-bar')\n",
    "> \n",
    "> fig.show() # USE `fig.show(renderer=\"png\")` FOR ALL GitHub and MarkUs SUBMISSIONS\n",
    "> ```\n",
    ">\n",
    "> _**Question Scope Warning**: we are not looking for any explanation realted to the mathematical equations for the line chosen for the **Simple Linear Regression** model by the \"ordinary least squares\" method, which happen to be_\n",
    "> \n",
    "> _$$\\hat \\beta_1 = r_{xy}\\frac{s_y}{s_x} \\quad \\text{ and } \\quad  \\hat\\beta_0 = \\bar {y}-\\hat \\beta_1\\bar {x}$$_\n",
    ">\n",
    "> _where $r_{xy}$ is the **correlation** between $x$ and $Y$ and $s_x$ and $s_Y$ are the **sample standard deviations** of $x$ and $y$_\n",
    ">\n",
    "> ---\n",
    "> \n",
    "> ```python \n",
    "> # Use this if you need it    \n",
    "> # https://stackoverflow.com/questions/52771328/plotly-chart-not-showing-in-jupyter-notebook\n",
    "> import plotly.offline as pyo\n",
    "> # Set notebook mode to work in offline\n",
    "> pyo.init_notebook_mode()    \n",
    "> ```\n",
    ">\n",
    "> ---\n",
    "> \n",
    "> _Don't forget to ask for summaries of all your different ChatBot sessions and organize and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatBot) But if you're using the STA130 custom NBLM ChatBot, you'll only be able to ask for summaries, of course!_  \n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "The fitted line in a regression model using the \"ordinary least squares\" (OLS) \n",
    "method is chosen to minimize the sum of the squared differences between the \n",
    "observed values and the predicted values (i.e., the residuals). \n",
    "This line is the one that best fits the data by minimizing the sum of \n",
    "squared residuals (SSR), where each residual is the difference between \n",
    "an observed Y value and the predicted Y value for each corresponding x.\n",
    "\n",
    "The reason it requires \"squares\" is that squaring the residuals ensures:\n",
    "\n",
    "All residuals contribute positively (as both negative and positive residuals \n",
    "would otherwise cancel each other out).\n",
    "Larger errors are penalized more: Larger deviations from the fitted line are \n",
    "given more weight, making the model more sensitive to outliers or significant deviations in the data.\n",
    "In simple terms, the OLS method chooses the line that minimizes the \"total squared error\" \n",
    "between the model’s predictions and the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99f3bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary:\n",
    "    The \"ordinary least squares\" (OLS) method chooses the fitted line \n",
    "    by minimizing the sum of squared differences between the observed \n",
    "    values and the predicted values (residuals). Squaring the residuals \n",
    "    ensures all errors are positive and gives more weight to larger \n",
    "    errors, making the model more sensitive to deviations. This results \n",
    "    in the line that best fits the data by minimizing the total squared \n",
    "    error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6589ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt link: https://chatgpt.com/share/672d5997-8c68-8008-aef3-c8b21a9e0a5a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dcdcd8",
   "metadata": {},
   "source": [
    "### 6. Explain why the first expression below can be interpreted as \"the proportion of variation in (outcome) Y explained by the model (i.e. _fitted_model.fittedvalues_)\"; and therefore, why _fitted_model.rsquared_ can be interpreted as a measure of the accuracy of the model; and, therefore what the two _np.corrcoef(...)[0,1]\\*\\*2_ expressions capture in the context of _Simple Linear Regression models_.\n",
    "\n",
    "1. `1-((Y-fitted_model.fittedvalues)**2).sum()/((Y-Y.mean())**2).sum()`\n",
    "2. `fitted_model.rsquared`\n",
    "3. `np.corrcoef(Y,fitted_model.fittedvalues)[0,1]**2`\n",
    "4. `np.corrcoef(Y,x)[0,1]**2`<br><br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _**R-squared** is the \"the proportion of variation in (outcome) $Y$ explained by the model ($\\hat y_i$)\" and is defined as_\n",
    ">\n",
    "> _$R^2 = 1 - \\frac{\\sum_{i=1}^n(Y_i-\\hat y)^2}{\\sum_{i=1}^n(Y_i-\\bar Y)^2}$_\n",
    ">\n",
    "> _The visuzation provided in the previous problem can be used to consider $(Y_i-\\bar Y)^2$ as the squared distance of the $Y_i$ to their sample average $\\bar Y$ as opposed to the squared **residuals** $(Y_i-\\hat y)^2$ which is the squared distance of the $Y_i$ to their fitted (predicted) values $Y_i$._\n",
    ">    \n",
    "> ---\n",
    "> \n",
    "> _Don't forget to ask for summaries of all your different ChatBot sessions and organize and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatBot) But if you're using the STA130 custom NBLM ChatBot, you'll only be able to ask for summaries, of course!_  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae2ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Explanation of Key Expressions in Simple Linear Regression:\n",
    "\n",
    "\"\"\"1. **First Expression: Proportion of Variation Explained by the Model**  \n",
    "   \\[\n",
    "   1 - \\frac{\\sum (Y - \\hat{Y})^2}{\\sum (Y - \\bar{Y})^2}\n",
    "   \\]\n",
    "   This expression calculates the **coefficient of determination**, or **\\( R^2 \\)**, \n",
    "   which represents the proportion of variance in the outcome variable \\( Y \\) that \n",
    "   is explained by the model. It compares:\n",
    "   - The **sum of squared residuals** \\( \\sum (Y - \\hat{Y})^2 \\), which measures the \n",
    "   discrepancy between the observed \\( Y \\) values and the predicted \\( Y \\) values \n",
    "   from the fitted model.\n",
    "   - The **total sum of squares** \\( \\sum (Y - \\bar{Y})^2 \\), which measures the total \n",
    "   variance in \\( Y \\) around its mean \\( \\bar{Y} \\).\n",
    "   \n",
    "   By subtracting the ratio of these two sums from 1, this expression gives the **proportion\n",
    "   of the variation** in \\( Y \\) that is explained by the regression model. A higher \\( R^2 \\)\n",
    "   means the model explains more of the variation in \\( Y \\), indicating better model accuracy.\n",
    "\n",
    "2. **fitted_model.rsquared**  \n",
    "   The **\\( R^2 \\)** value stored in `fitted_model.rsquared` is a summary measure of the\n",
    "   model's fit. It directly represents the proportion of variance in \\( Y \\) explained by \n",
    "   the predictors in the model. Higher values of \\( R^2 \\) indicate a better fit, meaning \n",
    "   the model does a good job of explaining the observed data.\n",
    "\n",
    "3. **np.corrcoef(Y, fitted_model.fittedvalues)[0,1]**²  \n",
    "   This expression calculates the **square of the correlation coefficient** between the \n",
    "   observed values \\( Y \\) and the predicted values (fitted values) from the model. The \n",
    "   correlation coefficient measures the linear relationship between \\( Y \\) and the \n",
    "   predicted values. Squaring the correlation coefficient gives the proportion of variance \n",
    "   in \\( Y \\) that is explained by the fitted values, which is essentially \\( R^2 \\).\n",
    "\n",
    "4. **np.corrcoef(Y, x)[0,1]**²  \n",
    "   This expression calculates the **square of the correlation coefficient** between the \n",
    "   observed values \\( Y \\) and the predictor values \\( x \\). It captures the strength of \n",
    "   the linear relationship between \\( Y \\) and \\( x \\). This value represents how much of \n",
    "   the variation in \\( Y \\) is associated with \\( x \\), without accounting for the full \n",
    "   model fit. It's generally smaller than the squared correlation between \\( Y \\) and the\n",
    "   fitted values because it doesn't consider the residual error explained by the model.\n",
    "   \"\"\"\n",
    "\n",
    "### Summary of Interpretations:\n",
    "\"\"\"\n",
    "- **\\( R^2 \\) (from the first expression and `fitted_model.rsquared`)**: The proportion of \n",
    "variation in \\( Y \\) explained by the model, indicating the model’s accuracy.\n",
    "- **Correlation squared between \\( Y \\) and fitted values**: Represents how much of the variation \n",
    "in \\( Y \\) is explained by the fitted model, similar to \\( R^2 \\).\n",
    "- **Correlation squared between \\( Y \\) and \\( x \\)**: Shows the strength of the relationship between \n",
    "the predictor \\( x \\) and \\( Y \\), but doesn’t account for the full model's explanatory power.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11436d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt link: https://chatgpt.com/share/672d5997-8c68-8008-aef3-c8b21a9e0a5a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a822c3",
   "metadata": {},
   "source": [
    "### 7. Indicate a couple of the assumptions of the *Simple Linear Regression* model specification that do not seem compatible with the example data below<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _Hint: What even ARE the assumptions of the  **Simple Linear Regression** model, you ask? Have a look at the mathematical specification and see if what it seems to be assuming._\n",
    "> \n",
    "> _Don't forget to ask for summaries of all your different ChatBot sessions and organize and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatBot) But if you're using the STA130 custom NBLM ChatBot, you'll only be able to ask for summaries, of course!_  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26dd319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# This data shows the relationship between the amount of fertilizer used and crop yield\n",
    "data = {'Amount of Fertilizer (kg) (x)': [1, 1.2, 1.4, 1.6, 1.8, 2, 2.2, 2.4, 2.6, \n",
    "                                          2.8, 3, 3.2, 3.4, 3.6, 3.8, 4, 4.2, 4.4, \n",
    "                                          4.6, 4.8, 5, 5.2, 5.4, 5.6, 5.8, 6, 6.2, \n",
    "                                          6.4, 6.6, 6.8, 7, 7.2, 7.4, 7.6, 7.8, 8, \n",
    "                                          8.2, 8.4, 8.6, 8.8,9, 9.2, 9.4, 9.6],\n",
    "        'Crop Yield (tons) (Y)': [18.7, 16.9, 16.1, 13.4, 48.4, 51.9, 31.8, 51.3, \n",
    "                                  63.9, 50.6, 58.7, 82.4, 66.7, 81.2, 96.5, 112.2, \n",
    "                                  132.5, 119.8, 127.7, 136.3, 148.5, 169.4, 177.9, \n",
    "                                  186.7, 198.1, 215.7, 230.7, 250.4, 258. , 267.8, \n",
    "                                  320.4, 302. , 307.2, 331.5, 375.3, 403.4, 393.5,\n",
    "                                  434.9, 431.9, 451.1, 491.2, 546.8, 546.4, 558.9]}\n",
    "df = pd.DataFrame(data)\n",
    "fig1 = px.scatter(df, x='Amount of Fertilizer (kg) (x)', y='Crop Yield (tons) (Y)',\n",
    "                  trendline='ols', title='Crop Yield vs. Amount of Fertilizer')\n",
    "\n",
    "# Perform linear regression using scipy.stats\n",
    "slope, intercept, r_value, p_value, std_err = \\\n",
    "    stats.linregress(df['Amount of Fertilizer (kg) (x)'], df['Crop Yield (tons) (Y)'])\n",
    "# Predict the values and calculate residuals\n",
    "y_hat = intercept + slope * df['Amount of Fertilizer (kg) (x)']\n",
    "residuals = df['Crop Yield (tons) (Y)'] - y_hat\n",
    "df['Residuals'] = residuals\n",
    "fig2 = px.histogram(df, x='Residuals', nbins=10, title='Histogram of Residuals',\n",
    "                    labels={'Residuals': 'Residuals'})\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2,\n",
    "                    subplot_titles=('Crop Yield vs. Amount of Fertilizer', \n",
    "                                    'Histogram of Residuals'))\n",
    "for trace in fig1.data:\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "for trace in fig2.data:\n",
    "    fig.add_trace(trace, row=1, col=2)\n",
    "fig.update_layout(title='Scatter Plot and Histogram of Residuals',\n",
    "    xaxis_title='Amount of Fertilizer (kg)', yaxis_title='Crop Yield (tons)',\n",
    "    xaxis2_title='Residuals', yaxis2_title='Frequency', showlegend=False)\n",
    "\n",
    "fig.show(renderer=\"png\") # USE `fig.show(renderer=\"png\")` FOR ALL GitHub and MarkUs SUBMISSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca347f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In the provided example, a **Simple Linear Regression** model is used to analyze the relationship between fertilizer \n",
    "usage and crop yield. However, the assumptions of the Simple Linear Regression model may not be fully satisfied based \n",
    "on the provided data and its visualizations. Here are a couple of key assumptions that might not align with the example data:\n",
    "\n",
    "### 1. **Linearity Assumption**  \n",
    "   - **Assumption**: The relationship between the predictor \\( x \\) (Amount of Fertilizer) and the outcome \\( Y \\) \n",
    "   (Crop Yield) should be linear. \n",
    "   - **Potential Issue**: From the scatter plot, it appears that the relationship might not be perfectly linear. While\n",
    "   there seems to be an increasing trend, the data shows some curvature, particularly at the extremes (lower and higher\n",
    "   amounts of fertilizer). This suggests a possible non-linear relationship that might not be captured well by a simple \n",
    "   linear model. A transformation of the predictor variable or a non-linear model might be more appropriate.\n",
    "   \n",
    "### 2. **Constant Variance of Errors (Homoscedasticity)**  \n",
    "   - **Assumption**: The residuals (differences between observed and predicted values) should have constant variance across\n",
    "   all levels of the predictor \\( x \\) (Amount of Fertilizer).\n",
    "   - **Potential Issue**: The histogram of residuals can indicate whether the variance of errors is constant \n",
    "   (homoscedasticity). If the residuals show a pattern (e.g., increasing spread as fertilizer amount increases), \n",
    "   this would suggest **heteroscedasticity**, meaning the variance of errors is not constant across all levels of \\( x \\). \n",
    "   This would violate the assumption of constant error variance and may indicate that the model is not the best fit for the data.\n",
    "\n",
    "### Conclusion:\n",
    "- The linearity assumption might not be fully satisfied due to potential curvature in the data.\n",
    "- There might be heteroscedasticity if the residuals' spread increases with higher levels of fertilizer, which would violate\n",
    "the constant variance assumption.\n",
    "\n",
    "To improve the model, further diagnostic tests or alternative models (e.g., polynomial regression) might be needed.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a905641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt link: https://chatgpt.com/share/672d5997-8c68-8008-aef3-c8b21a9e0a5a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae88481",
   "metadata": {},
   "source": [
    "## \"Week of Nov04\" HW [due prior to the Nov08 TUT]\n",
    "\n",
    "_**In place of the \"Data Analysis Assignment\" format we introduced for the previous weeks' HW, the remaining questions will be a collection of exercises based around the following data**_\n",
    "\n",
    "> The details of the \"LOWESS Trendline\" shown below are not a part of the intended scope of the activities here, but it is included since it is suggestive of the questions we will consider and address here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb5d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# The \"Classic\" Old Faithful Geyser dataset: ask a ChatBot for more details if desired\n",
    "old_faithful = sns.load_dataset('geyser')\n",
    "\n",
    "# Create a scatter plot with a Simple Linear Regression trendline\n",
    "fig = px.scatter(old_faithful, x='waiting', y='duration', \n",
    "                 title=\"Old Faithful Geyser Eruptions\", \n",
    "                 trendline='ols')#'lowess'\n",
    "\n",
    "# Add a smoothed LOWESS Trendline to the scatter plot\n",
    "lowess = sm.nonparametric.lowess  # Adjust 'frac' to change \"smoothness bandwidth\"\n",
    "smoothed = lowess(old_faithful['duration'], old_faithful['waiting'], frac=0.25)  \n",
    "smoothed_df = pd.DataFrame(smoothed, columns=['waiting', 'smoothed_duration'])\n",
    "fig.add_scatter(x=smoothed_df['waiting'], y=smoothed_df['smoothed_duration'], \n",
    "                mode='lines', name='LOWESS Trendline')\n",
    "\n",
    "fig.show(renderer=\"png\") # USE `fig.show(renderer=\"png\")` FOR ALL GitHub and MarkUs SUBMISSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778e0c13",
   "metadata": {},
   "source": [
    "### 8. Specify a *null hypothesis* of \"no linear association (on average)\" in terms of the relevant *parameter* of the *Simple Linear Regression* model, and use the code below to characterize the evidence in the data relative to the *null hypothesis* and interpret your subsequent beliefs regarding the Old Faithful Geyser dataset.<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _Remember that **Hypothesis Testing** is not a \"mathematical proof\"_\n",
    ">\n",
    "> - _We do not prove $H_0$ false, we instead give evidence against the $H_0$: \"We reject the null hypothesis with a p-value of XYZ, meaning we have ABC evidence against the null hypothesis\"_\n",
    "> - _We do not prove $H_0$ is true, we instead do not have evidence to reject $H_0$: \"We fail to reject the null hypothesis with a p-value of XYZ\"_\n",
    "\n",
    "|p-value|Evidence|\n",
    "|-|-|\n",
    "|$$p > 0.1$$|No evidence against the null hypothesis|\n",
    "|$$0.1 \\ge p > 0.05$$|Weak evidence against the null hypothesis|\n",
    "|$$0.05 \\ge p > 0.01$$|Moderate evidence against the null hypothesis|\n",
    "|$$0.01 \\ge p > 0.001$$|Strong evidence against the null hypothesis|\n",
    "|$$0.001 \\ge p$$|Very strong evidence against the null hypothesis|\n",
    "\n",
    "</details>    \n",
    "\n",
    "> ```python\n",
    "> import seaborn as sns\n",
    "> import statsmodels.formula.api as smf\n",
    ">\n",
    "> # The \"Classic\" Old Faithful Geyser dataset\n",
    "> old_faithful = sns.load_dataset('geyser')\n",
    "> \n",
    "> linear_for_specification = 'duration ~ waiting'\n",
    "> model = smf.ols(linear_for_specification, data=old_faithful)\n",
    "> fitted_model = model.fit()\n",
    "> fitted_model.summary()\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37b75dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt link: https://chatgpt.com/share/672d71a6-fa44-8008-90b2-ea0999abf830\n",
    "summary:\n",
    "The null hypothesis for a simple linear regression model between eruption duration (`duration`) and \n",
    "waiting time (`waiting`) is that there is no linear association, i.e., \\(\\beta_1 = 0\\). \n",
    "\n",
    "Using the Old Faithful Geyser dataset and fitting the model, the p-value for the slope is examined. \n",
    "If the p-value is less than the significance level (e.g., 0.05), we reject the null hypothesis, \n",
    "indicating a significant linear relationship.\n",
    "\n",
    "For example, if the p-value is 0.000 (as in the hypothetical output), we reject the null hypothesis \n",
    "and conclude that there is a statistically significant positive linear association between waiting time \n",
    "and eruption duration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799d9d71",
   "metadata": {},
   "source": [
    "### 9. As seen in the introductory figure above, if the delay of the geyser eruption since the previous geyser eruption exceeds approximately 63 minutes, there is a notable increase in the duration of the geyser eruption itself. In the figure below we therefore restrict the dataset to only short wait times. Within the context of only short wait times, is there evidence in the data for a relationship between duration and wait time in the same manner as in the full data set? Using the following code, characterize the evidence against the *null hypothesis* in the context of short wait times which are less than  *short_wait_limit* values of *62*, *64*, *66*.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf57b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "short_wait_limit = 62 # 64 # 66 #\n",
    "short_wait = old_faithful.waiting < short_wait_limit\n",
    "\n",
    "print(smf.ols('duration ~ waiting', data=old_faithful[short_wait]).fit().summary().tables[1])\n",
    "\n",
    "# Create a scatter plot with a linear regression trendline\n",
    "fig = px.scatter(old_faithful[short_wait], x='waiting', y='duration', \n",
    "                 title=\"Old Faithful Geyser Eruptions for short wait times (<\"+str(short_wait_limit)+\")\", \n",
    "                 trendline='ols')\n",
    "\n",
    "fig.show(renderer=\"png\") # USE `fig.show(renderer=\"png\")` FOR ALL GitHub and MarkUs SUBMISSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50616527",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To assess whether there is evidence of a relationship between the geyser eruption duration \n",
    "(`duration`) and the wait time (`waiting`) within the context of short wait times, you will \n",
    "be using a linear regression model for various values of `short_wait_limit` (62, 64, and 66 minutes). \n",
    "The null hypothesis is that there is no relationship between `duration` and `waiting`, i.e., \n",
    "the slope of the regression line is zero. \n",
    "\n",
    "Here’s how you can interpret the results from the code and output:\n",
    "\n",
    "### Steps for Evaluation:\n",
    "\n",
    "1. **Define the Short Wait Condition:**\n",
    "   The code filters the dataset to include only those observations where the `waiting` time is less \n",
    "   than the chosen `short_wait_limit`. This is achieved through the condition `old_faithful.waiting < short_wait_limit`.\n",
    "\n",
    "2. **Run the Linear Regression:**\n",
    "   The linear regression is performed with the formula `duration ~ waiting` using `statsmodels`' `ols` \n",
    "   function. This estimates the relationship between `waiting` time and `duration` of the eruption under \n",
    "   the short wait condition.\n",
    "\n",
    "3. **Summarize the Output:**\n",
    "   After fitting the model, the `fit().summary().tables[1]` will display a table with statistical details, such as:\n",
    "   - **Coefficient for `waiting`:** Indicates the slope of the regression line.\n",
    "   - **p-value for `waiting`:** Tests the null hypothesis that the slope is zero (no relationship). A low \n",
    "   p-value (typically < 0.05) suggests strong evidence against the null hypothesis.\n",
    "   - **R-squared value:** Represents how much of the variation in `duration` is explained by `waiting`. \n",
    "\n",
    "4. **Scatter Plot with Trendline:**\n",
    "   The `plotly` scatter plot will visualize the data points along with the linear regression trendline. \n",
    "   This will help you visually assess if there is an apparent relationship between the variables.\n",
    "\n",
    "### Example Analysis for `short_wait_limit = 62`:\n",
    "\n",
    "For example, if the p-value for the coefficient of `waiting` is less than 0.05, this would indicate a \n",
    "statistically significant relationship between `waiting` and `duration` within the group of short wait \n",
    "times (under 62 minutes). The R-squared value would show how much of the variation in `duration` is \n",
    "explained by the variation in `waiting`.\n",
    "\n",
    "### Expected Output:\n",
    "1. **Coefficients**:\n",
    "   - If the coefficient of `waiting` is significantly positive, this means that as the waiting time increases, \n",
    "   the eruption duration tends to increase (within short wait times).\n",
    "   \n",
    "2. **p-value**:\n",
    "   - A p-value < 0.05 (or whatever significance level you choose) suggests evidence against the null hypothesis, \n",
    "   indicating a significant relationship between the variables in the short wait time range.\n",
    "\n",
    "3. **R-squared**:\n",
    "   - This value shows the proportion of variance in the eruption duration explained by the waiting time. \n",
    "   A higher value (close to 1) indicates a stronger linear relationship.\n",
    "\n",
    "### Comparison:\n",
    "By running the regression for each value of `short_wait_limit` (62, 64, 66), you can compare whether the \n",
    "relationship remains consistent or changes as you widen the range of \"short wait\" times.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b19eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt link: https://chatgpt.com/share/672d747c-9e1c-8008-abcc-5ef73144b5fd\n",
    "summary:\n",
    "To assess the relationship between geyser eruption duration and wait time for short wait times (less than 62, 64, or 66 minutes), you will:\n",
    "\n",
    "1. **Filter the Data**: Limit the dataset to cases where `waiting < short_wait_limit`.\n",
    "2. **Run a Linear Regression**: Fit the model `duration ~ waiting` using `statsmodels`, testing if the slope (relationship between `waiting` \n",
    "and `duration`) is significantly different from zero.\n",
    "3. **Interpret the Results**:\n",
    "   - **p-value**: If < 0.05, reject the null hypothesis, indicating a significant relationship.\n",
    "   - **Coefficient for `waiting`**: A positive value suggests a positive relationship (longer wait times lead to longer eruptions).\n",
    "   - **R-squared**: Shows how much of the variation in `duration` is explained by `waiting`.\n",
    "\n",
    "Finally, the scatter plot with a regression trendline will help visualize the relationship. By comparing results for `short_wait_limit` \n",
    "values of 62, 64, and 66, you can determine if the relationship holds across different ranges of short wait times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a7d64b",
   "metadata": {},
   "source": [
    "### 10. Let's now consider just the (*n=160*) long wait times (as specified in the code below), and write code to do the following:\n",
    "\n",
    "1. create fitted **Simple Linear Regression** models for **boostrap samples** and collect and visualize the **bootstrapped sampling distribution** of the **fitted slope coefficients** of the fitted models;  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b4bda7",
   "metadata": {},
   "source": [
    "2. **simulate** samples (of size `n=160`) from a **Simple Linear Regression** model that uses $\\beta_0 = 1.65$, $\\beta_1 = 0$, $\\sigma = 0.37$ along with the values of `waiting` for $x$ to create **simuations** of $Y$ and use these collect and visualize the **sampling distribution** of the **fitted slope coefficient** under a **null hypothesis** assumption of \"no linear association (on average)\"; then,  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc24ecd",
   "metadata": {},
   "source": [
    "3. report if $0$ is contained within a 95\\% **bootstrapped confidence interval**; and if the **simulated p-value** matches `smf.ols('duration ~ waiting', data=old_faithful[long_wait]).fit().summary().tables[1]`?<br><br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _You'll need to create `for` loops to repeatedly create fitted **Simple Linear Regression** models using different samples, collecting the **fitted slope coeffient** created in each `for` loop \"step\" in order to visualize the **simulated sampling distributions**_\n",
    "> \n",
    "> - _A **bootstrapped sample** of the \"long wait times\" dataset can be created with `old_faithful[long_wait].sample(n=long_wait.sum(), replace=True)`_\n",
    ">\n",
    ">\n",
    "> - _A **simulated** version of the \"long wait times under a null hypothesis assumption of **no linear association (on average)**\" dataset can be created by first creating `old_faithful_simulation = old_faithful[long_wait].copy()` and then assigning the **simulated** it values with `old_faithful_simulation['duration'] = 1.65 + 0*old_faithful_simulation.waiting + stats.norm(loc=0, scale=0.37).rvs(size=long_wait.sum())`_ \n",
    ">\n",
    ">  _The values $\\beta_0 = 1.65$ and $\\sigma = 0.37$ are chosen to match what is actually observed in the data, while $\\beta_1 = 0$ is chosen to reflect a **null hypothesis** assumption of \"no linear assocaition (on average)\"; and, make sure that you understand why it is that_\n",
    ">\n",
    ">\n",
    "> - _if `bootstrapped_slope_coefficients` is the `np.array` of your **bootstrapped slope coefficients** then `np.quantile(bootstrapped_slope_coefficients, [0.025, 0.975])` is a 95\\% **bootstrapped confidence interval**_\n",
    "> \n",
    ">\n",
    "> - _if `simulated_slope_coefficients` is the `np.array` of your **fitted slope coefficients** **simulated** under a **null hypothesis** \"no linear association (on average)\" then `(np.abs(simulated_slope_coefficients) >= smf.ols('duration ~ waiting', data=old_faithful[long_wait]).fit().params[1]).mean()` is the **p-value** for the **simulated** **simulated sampling distribution of the slope coeficients** under a **null hypothesis** \"no linear association (on average)\"_\n",
    "\n",
    "</details>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce9a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "long_wait_limit = 71\n",
    "long_wait = old_faithful.waiting > long_wait_limit\n",
    "\n",
    "print(smf.ols('duration ~ waiting', data=old_faithful[long_wait]).fit().summary().tables[1])\n",
    "\n",
    "# Create a scatter plot with a linear regression trendline\n",
    "fig = px.scatter(old_faithful[long_wait], x='waiting', y='duration', \n",
    "                 title=\"Old Faithful Geyser Eruptions for short wait times (>\"+str(long_wait_limit)+\")\", \n",
    "                 trendline='ols')\n",
    "fig.show() # USE `fig.show(renderer=\"png\")` FOR ALL GitHub and MarkUs SUBMISSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d17663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'old_faithful' is a pandas DataFrame and 'long_wait' is the filtering condition\n",
    "long_wait_limit = 71\n",
    "long_wait = old_faithful.waiting > long_wait_limit\n",
    "\n",
    "# 1. Bootstrap procedure\n",
    "n_bootstraps = 1000\n",
    "bootstrapped_slopes = []\n",
    "\n",
    "# Perform bootstrapping\n",
    "for _ in range(n_bootstraps):\n",
    "    bootstrap_sample = old_faithful[long_wait].sample(n=160, replace=True)\n",
    "    model = smf.ols('duration ~ waiting', data=bootstrap_sample).fit()\n",
    "    bootstrapped_slopes.append(model.params['waiting'])\n",
    "\n",
    "# Visualize the bootstrapped sampling distribution of the slope\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(bootstrapped_slopes, bins=30, edgecolor='black')\n",
    "plt.title('Bootstrapped Sampling Distribution of the Fitted Slope Coefficient')\n",
    "plt.xlabel('Slope Coefficient')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab3337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'old_faithful' is a pandas DataFrame and 'long_wait' is the filtering condition\n",
    "long_wait_limit = 71\n",
    "long_wait = old_faithful.waiting > long_wait_limit\n",
    "\n",
    "# 2. Simulating samples under the null hypothesis (β1 = 0)\n",
    "n_simulations = 1000\n",
    "simulated_slopes = []\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Simulate data under the null hypothesis (β1 = 0)\n",
    "beta_0 = 1.65\n",
    "beta_1 = 0\n",
    "sigma = 0.37\n",
    "waiting_values = old_faithful[long_wait].waiting\n",
    "\n",
    "for _ in range(n_simulations):\n",
    "    simulated_Y = beta_0 + beta_1 * waiting_values + np.random.normal(0, sigma, size=160)\n",
    "    simulation_data = pd.DataFrame({'waiting': waiting_values, 'duration': simulated_Y})\n",
    "    model = smf.ols('duration ~ waiting', data=simulation_data).fit()\n",
    "    simulated_slopes.append(model.params['waiting'])\n",
    "\n",
    "# Visualize the sampling distribution of the simulated slope coefficient\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(simulated_slopes, bins=30, edgecolor='black', color='lightblue')\n",
    "plt.title('Sampling Distribution of the Fitted Slope Coefficient (Null Hypothesis)')\n",
    "plt.xlabel('Slope Coefficient')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49479af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'old_faithful' is a pandas DataFrame and 'long_wait' is the filtering condition\n",
    "long_wait_limit = 71\n",
    "long_wait = old_faithful.waiting > long_wait_limit\n",
    "\n",
    "# Assuming the bootstrapped slopes have already been collected in the variable 'bootstrapped_slopes'\n",
    "\n",
    "# 3. Report if 0 is within the 95% bootstrapped confidence interval\n",
    "lower_bound = np.percentile(bootstrapped_slopes, 2.5)\n",
    "upper_bound = np.percentile(bootstrapped_slopes, 97.5)\n",
    "\n",
    "# Report the result\n",
    "print(f\"95% Bootstrapped Confidence Interval: ({lower_bound:.4f}, {upper_bound:.4f})\")\n",
    "if lower_bound <= 0 <= upper_bound:\n",
    "    print(\"0 is within the 95% bootstrapped confidence interval.\")\n",
    "else:\n",
    "    print(\"0 is NOT within the 95% bootstrapped confidence interval.\")\n",
    "\n",
    "# Simulated p-value calculation from the slope distribution under the null hypothesis\n",
    "observed_slope = smf.ols('duration ~ waiting', data=old_faithful[long_wait]).fit().params['waiting']\n",
    "simulated_p_value = np.mean(np.abs(np.array(simulated_slopes)) >= np.abs(observed_slope))\n",
    "\n",
    "# Compare the simulated p-value with the summary\n",
    "print(f\"Simulated p-value: {simulated_p_value:.4f}\")\n",
    "print(\"Model Summary P-value:\")\n",
    "print(smf.ols('duration ~ waiting', data=old_faithful[long_wait]).fit().summary().tables[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb1b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Here’s a summary of the three distinct code blocks:\n",
    "\n",
    "1. **Bootstrap Sampling Distribution of Slope Coefficients**:\n",
    "   - This code performs **bootstrapping** on the `old_faithful` dataset by resampling with replacement, fitting a **Simple Linear Regression** model on each sample, and collecting the **slope coefficients**. The histogram visualizes the distribution of these bootstrapped slopes.\n",
    "\n",
    "2. **Simulating Data Under the Null Hypothesis (β₁ = 0)**:\n",
    "   - This code **simulates** response variables (`Y`) based on a **Simple Linear Regression** model where the slope (\\( \\beta_1 \\)) is set to 0 (no linear relationship). It generates multiple simulations and collects the **slope coefficients** from fitting models to each simulated dataset. The distribution of these coefficients is visualized.\n",
    "\n",
    "3. **Confidence Interval and Simulated p-value**:\n",
    "   - This code **calculates** the 95% **bootstrapped confidence interval** for the slope coefficients and checks if 0 is within that interval. It also calculates the **simulated p-value** by comparing the observed slope from the actual model to the simulated slopes under the null hypothesis, and compares it with the p-value from the model summary.\n",
    "\n",
    "These three blocks work together to examine the relationship between waiting times and eruption durations for the Old Faithful dataset by using **bootstrapping**, **simulations**, and **hypothesis testing**.Here’s a summary of the three distinct code blocks:\n",
    "\n",
    "1. **Bootstrap Sampling Distribution of Slope Coefficients**:\n",
    "   - This code performs **bootstrapping** on the `old_faithful` dataset by resampling with replacement, fitting a **Simple Linear Regression** model on each sample, and collecting the **slope coefficients**. The histogram visualizes the distribution of these bootstrapped slopes.\n",
    "\n",
    "2. **Simulating Data Under the Null Hypothesis (β₁ = 0)**:\n",
    "   - This code **simulates** response variables (`Y`) based on a **Simple Linear Regression** model where the slope (\\( \\beta_1 \\)) is set to 0 (no linear relationship). It generates multiple simulations and collects the **slope coefficients** from fitting models to each simulated dataset. The distribution of these coefficients is visualized.\n",
    "\n",
    "3. **Confidence Interval and Simulated p-value**:\n",
    "   - This code **calculates** the 95% **bootstrapped confidence interval** for the slope coefficients and checks if 0 is within that interval. It also calculates the **simulated p-value** by comparing the observed slope from the actual model to the simulated slopes under the null hypothesis, and compares it with the p-value from the model summary.\n",
    "\n",
    "These three blocks work together to examine the relationship between waiting times and eruption durations for the Old Faithful dataset by using **bootstrapping**, **simulations**, and **hypothesis testing**.\n",
    "\"\"\"\n",
    "chatgpt link: https://chatgpt.com/share/672d76df-5f98-8008-b08b-66fe18a75a9b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d37dc",
   "metadata": {},
   "source": [
    "### 11. Since we've considered wait times of around <64  \"short\" and wait times of >71 \"long\", let's instead just divide the data and insead call wait times of <68 \"short\" and otherwise just call them \"long\". Consider the *Simple Linear Regression* model specification using an *indicator variable* of the wait time length<br>\n",
    "\n",
    "$$\\large Y_i = \\beta_{\\text{intercept}} + 1_{[\\text{\"long\"}]}(\\text{k_i})\\beta_{\\text{contrast}} + \\epsilon_i \\quad \\text{ where } \\quad \\epsilon_i \\sim \\mathcal N\\left(0, \\sigma\\right)$$\n",
    "\n",
    "### where we use $k_i$ (rather than $x_i$) (to refer to the \"kind\" or \"katagory\" or \"kontrast\") column (that you may have noticed was already a part) of the original dataset; and, explain the \"big picture\" differences between this model specification and the previously considered model specifications<br>\n",
    "\n",
    "1. `smf.ols('duration ~ waiting', data=old_faithful)`\n",
    "2. `smf.ols('duration ~ waiting', data=old_faithful[short_wait])`\n",
    "3. `smf.ols('duration ~ waiting', data=old_faithful[long_wait])`\n",
    "\n",
    "### and report the evidence against a *null hypothesis* of \"no difference between groups \"on average\") for the new *indicator variable* based model<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758121fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "display(smf.ols('duration ~ C(kind, Treatment(reference=\"short\"))', data=old_faithful).fit().summary().tables[1])\n",
    "\n",
    "fig = px.box(old_faithful, x='kind', y='duration', \n",
    "             title='duration ~ kind',\n",
    "             category_orders={'kind': ['short', 'long']})\n",
    "fig.show(renderer=\"png\") # USE `fig.show(renderer=\"png\")` FOR ALL GitHub and MarkUs SUBMISSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd0bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this modified model specification, you're using an indicator variable (`kind`) to categorize the wait times into two groups: \"short\" (wait time < 68) and \"long\" (wait time ≥ 68). The model becomes:\n",
    "\n",
    "\\[\n",
    "Y_i = \\beta_{\\text{intercept}} + 1[\\text{long}](k_i) \\beta_{\\text{contrast}} + \\epsilon_i\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "\n",
    "- \\( Y_i \\) is the duration for the \\( i \\)-th observation.\n",
    "- \\( k_i \\) is the indicator variable representing the kind of wait time (\"short\" or \"long\").\n",
    "- \\( 1[\\text{long}](k_i) \\) is a binary indicator for the \"long\" wait time group (1 if \"long\", 0 if \"short\").\n",
    "- \\( \\beta_{\\text{intercept}} \\) is the intercept term, representing the average duration for the \"short\" wait time group.\n",
    "- \\( \\beta_{\\text{contrast}} \\) is the coefficient for the \"long\" wait time group, measuring the difference in the average duration between \"long\" and \"short\" groups.\n",
    "- \\( \\epsilon_i \\sim \\mathcal{N}(0, \\sigma) \\) is the error term with a mean of 0 and variance \\( \\sigma^2 \\).\n",
    "\n",
    "### Big Picture Differences\n",
    "1. **Indicator Variable Model**:\n",
    "   - This model uses a binary indicator to model the difference between two groups (\"short\" and \"long\"), with the intercept representing the \"short\" group and the coefficient \\( \\beta_{\\text{contrast}} \\) representing the difference for the \"long\" group.\n",
    "   - It allows a more direct interpretation of the difference between \"short\" and \"long\" durations as opposed to fitting the model for each group separately.\n",
    "\n",
    "2. **Previous Models**:\n",
    "   - In the previous models (`smf.ols('duration ~ waiting', data=old_faithful)`), a continuous variable was used, which assumes a linear relationship between wait times and durations. The focus is on predicting duration based on a continuous wait time predictor, regardless of any inherent grouping or categorization of the wait times.\n",
    "   - In the models with separate subsets (`smf.ols('duration ~ waiting', data=old_faithful[short_wait])`, etc.), the data was split, and separate models were fit for each group (\"short\" and \"long\"). This results in a piecewise linear relationship and doesn't allow for a direct comparison between the groups within a single framework.\n",
    "\n",
    "3. **Key Statistical Comparison**:\n",
    "   - The new indicator variable model directly compares the average duration between the two groups using the contrast term \\( \\beta_{\\text{contrast}} \\). The null hypothesis for this model is \\( H_0: \\beta_{\\text{contrast}} = 0 \\), meaning there's no difference in the average duration between the \"short\" and \"long\" wait times.\n",
    "   - The previous separate models fit different relationships for each group and require manual comparison of coefficients or separate hypothesis tests to assess group differences.\n",
    "\n",
    "### Evidence Against Null Hypothesis\n",
    "You can test the null hypothesis \\( H_0: \\beta_{\\text{contrast}} = 0 \\) by looking at the p-value for the contrast term in the model output. If the p-value is small (typically below 0.05), you reject the null hypothesis, suggesting there is a significant difference between the \"short\" and \"long\" wait time groups on average.\n",
    "\n",
    "To perform this in your code, you would examine the table generated by `smf.ols('duration ~ C(kind, Treatment(reference=\"short\"))', data=old_faithful).fit().summary().tables[1]`, where the p-value for \\( \\beta_{\\text{contrast}} \\) will tell you if there's strong evidence against the null hypothesis of no difference between the groups.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc029b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(old_faithful, x='kind', y='duration', \n",
    "             title='duration ~ kind',\n",
    "             category_orders={'kind': ['short', 'long']})\n",
    "fig.show(renderer=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f96dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary:\n",
    "    \"\"\"\n",
    "    In this session, you focused on specifying a **Simple Linear Regression** model with an **indicator variable** to categorize wait times as \"short\" (less than 68 minutes) and \"long\" (68 minutes or more). The model is structured as:\n",
    "\n",
    "\\[\n",
    "Y_i = \\beta_{\\text{intercept}} + 1[\\text{long}](k_i) \\beta_{\\text{contrast}} + \\epsilon_i\n",
    "\\]\n",
    "\n",
    "Here, the indicator variable \\( k_i \\) distinguishes between the two wait time categories, and the contrast term \\( \\beta_{\\text{contrast}} \\) quantifies the difference in average durations between the \"long\" and \"short\" groups.\n",
    "\n",
    "### Key Points:\n",
    "- **Indicator Variable Model**: Directly models the difference between \"short\" and \"long\" wait times using an indicator, with \\( \\beta_{\\text{intercept}} \\) representing the \"short\" group and \\( \\beta_{\\text{contrast}} \\) representing the difference for the \"long\" group.\n",
    "- **Previous Models**: Used continuous wait times or separate models for each group, requiring more manual comparisons between groups.\n",
    "- **Null Hypothesis**: The null hypothesis \\( H_0: \\beta_{\\text{contrast}} = 0 \\) tests whether there's no difference between the two groups on average. A small p-value suggests rejecting this hypothesis.\n",
    "- **Visualization**: A boxplot was used to visually compare the durations for \"short\" and \"long\" wait times, helping in the intuitive understanding of group differences.\n",
    "\n",
    "This approach provides a more efficient and direct comparison between the two groups, with a clearer statistical interpretation through the model's contrast term and hypothesis testing.\n",
    "    \"\"\"\n",
    "chatgpt link: https://chatgpt.com/share/672d77f6-d97c-8008-a18b-8e8a09229862"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797934c8",
   "metadata": {},
   "source": [
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _Don't forget to ask for summaries of all your different ChatBot sessions and organize and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatBot) But if you're using the STA130 custom NBLM ChatBot, you'll only be able to ask for summaries, of course!_  \n",
    "</details>\n",
    "\n",
    "### 12. Identify which of the histograms suggests the plausibility of the assumption that the distribution of *error* terms is normal for each of the models, and explain why the other three do not support this assumption.\n",
    "\n",
    "> Hint: Question 5 of the *Communication Activity #2* of the Oct25 TUT (addressing an *omitted* section of the TUT) discusses how the assumption in *Simple Linear Regression* that the *error* terms $\\epsilon_i \\sim \\mathcal N\\left(0, \\sigma\\right)$ is diagnostically assessed by evaluating distributional shape of the *residuals* $\\text{e}_i = \\hat \\epsilon_i = Y_i - \\hat y_i$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03792467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "model_residuals = {\n",
    "    '<br>Model 1:<br>All Data using slope': smf.ols('duration ~ waiting', data=old_faithful).fit().resid,\n",
    "    '<br>Model 2:<br>Short Wait Data': smf.ols('duration ~ waiting', data=old_faithful[short_wait]).fit().resid,\n",
    "    '<br>Model 3:<br>Long Wait Data': smf.ols('duration ~ waiting', data=old_faithful[long_wait]).fit().resid,\n",
    "    '<br>Model 4:<br>All Data using indicator': smf.ols('duration ~ C(kind, Treatment(reference=\"short\"))', data=old_faithful).fit().resid\n",
    "}\n",
    "\n",
    "fig = make_subplots(rows=2, cols=2, subplot_titles=list(model_residuals.keys()))\n",
    "for i, (title, resid) in enumerate(model_residuals.items()):\n",
    "\n",
    "    if i == 1:  # Apply different bins only to the second histogram (index 1)\n",
    "        bin_size = dict(start=-1.9, end=1.9, size=0.2)\n",
    "    else:\n",
    "        bin_size = dict(start=-1.95, end=1.95, size=0.3)\n",
    "\n",
    "    fig.add_trace(go.Histogram(x=resid, name=title, xbins=bin_size, histnorm='probability density'), \n",
    "                  row=int(i/2)+1, col=(i%2)+1)\n",
    "    fig.update_xaxes(title_text=\"n=\"+str(len(resid)), row=int(i/2)+1, col=(i%2)+1)    \n",
    "    \n",
    "    normal_range = np.arange(-3*resid.std(),3*resid.std(),0.01)\n",
    "    fig.add_trace(go.Scatter(x=normal_range, mode='lines', opacity=0.5,\n",
    "                             y=stats.norm(loc=0, scale=resid.std()).pdf(normal_range),\n",
    "                             line=dict(color='black', dash='dot', width=2),\n",
    "                             name='Normal Distribution<br>(99.7% of its area)'), \n",
    "                  row=int(i/2)+1, col=(i%2)+1)\n",
    "    \n",
    "fig.update_layout(title_text='Histograms of Residuals from Different Models')\n",
    "fig.update_xaxes(range=[-2,2])\n",
    "fig.show(renderer=\"png\") # USE `fig.show(renderer=\"png\")` FOR ALL GitHub and MarkUs SUBMISSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee40ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary:\n",
    "    \"\"\"\n",
    "    To assess which histogram supports the assumption of normally distributed error terms:\n",
    "\n",
    "- **Model 1 (All Data using Slope)**: If the histogram closely follows a bell-shaped curve with the residuals aligning with the normal distribution line, it supports normality.\n",
    "- **Model 2 (Short Wait Data)**: If the histogram is skewed or multi-modal, it suggests non-normality.\n",
    "- **Model 3 (Long Wait Data)**: Similar to Model 2, if the histogram shows skewness or kurtosis, it does not support normality.\n",
    "- **Model 4 (All Data using Indicator)**: If the histogram shows patterns, clusters, or heavy tails, it suggests non-normality, especially with categorical predictors.\n",
    "\n",
    "**The model with the most bell-shaped, symmetric histogram aligning with the normal distribution line supports the normality assumption.**\n",
    "    \"\"\"\n",
    "chatgpt link: https://chatgpt.com/share/672d7861-0f4c-8008-b367-93060ab32bbc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289f257f",
   "metadata": {},
   "source": [
    "### 13. The \"short\" and \"long\" wait times are not \"before and after\" measurements so there are not natural pairs on which to base differences on which to do a \"one sample\" (paired differences) *hypothesis test*; but, we can do \"two sample\" hypothesis testing using a *permuation test*, or create a 95% *bootstrap confidence interval* for the difference in means of the two populations. \n",
    "\n",
    "### (A) Do a permuation test $\\;H_0: \\mu_{\\text{short}}=\\mu_{\\text{long}} \\; \\text{ no difference in duration between short and long groups}$ by \"shuffling\" the labels\n",
    "### (B) Create a 95% bootstrap confidence interval  by repeatedly bootstrapping within each group and applying *np.quantile(bootstrapped_mean_differences, [0.025, 0.975])* to the collection of differences between the sample means.    \n",
    "### (a) Explain how the sampling approaches work for the two simulations.\n",
    "### (b) Compare and contrast these two methods with the *indicator variable* based model approach used in Question 11, explaining how they're similar and different.<br>\n",
    "    \n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _You'll need to create `for` loops for repeated (shuffling simulation) **permutation** and (subgroup) **bootstrapping**, where_\n",
    ">\n",
    "> - _\"shuffling\" for **permutation testing** is done like this `old_faithful.assign(kind_shuffled=old_faithful['kind'].sample(n=len(old_faithful), replace=False).values)#.groupby('kind').size()`; then, the **mean difference statistic** is then calculated using `.groupby('kind_shuffled')['duration'].mean().iloc[::-1].diff().values[1]` (so the **observed statistic** is `old_faithful.groupby('kind')['duration'].mean().iloc[::-1].diff().values[1]`_\n",
    "> \n",
    ">\n",
    "> - _\"two sample\" **bootstrapping** is done like this `old_faithful.groupby('kind').apply(lambda x: x.sample(n=len(x), replace=True)).reset_index(drop=True)#.groupby('kind').size()`; then, the **bootstrapped mean difference statistic** is then calculated using `.groupby('kind')['duration'].mean().iloc[::-1].diff().values[1]` (like the **observed statistic** except this is applied to the **bootstrapped** resampling of `old_faithful`)_\n",
    "> ---\n",
    "> \n",
    "> _Don't forget to ask for summaries of all your different ChatBot sessions and organize and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatBot) But if you're using the STA130 custom NBLM ChatBot, you'll only be able to ask for summaries, of course!_\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6331bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary:\n",
    "\"\"\"\n",
    "### Summary:\n",
    "\n",
    "1. **Permutation Test**:\n",
    "   - **Null hypothesis**: No difference in means between short and long wait times.\n",
    "   - **Method**: Shuffle the labels between the two groups, calculate the mean differences for each shuffle, and compare the observed difference to the shuffled distribution to calculate a p-value.\n",
    "\n",
    "2. **Bootstrap Confidence Interval**:\n",
    "   - **Method**: Resample with replacement from each group, compute the mean differences for each resample, and create a distribution of mean differences. The 95% confidence interval is the 2.5th and 97.5th percentiles of this distribution.\n",
    "\n",
    "### (a) How They Work:\n",
    "- **Permutation test**: Builds a distribution of mean differences under the null hypothesis by shuffling the group labels.\n",
    "- **Bootstrap CI**: Builds an empirical distribution of mean differences by resampling within each group and calculating the difference in means for each sample.\n",
    "\n",
    "### (b) Comparison with Indicator Variable Approach:\n",
    "- **Similarity**: All three methods assess the difference between the two groups.\n",
    "- **Difference**:\n",
    "  - **Permutation**: Non-parametric, doesn't rely on distribution assumptions.\n",
    "  - **Bootstrap**: Estimates the uncertainty of the mean difference directly from data, without assuming normality.\n",
    "  - **Indicator model**: Assumes linearity and error structure, testing differences using regression but with model assumptions about the data distribution.\n",
    "\n",
    "The permutation and bootstrap methods are more flexible and non-parametric compared to the indicator variable-based model, which relies on specific data assumptions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed377c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt link: https://chatgpt.com/share/672d78b8-3e34-8008-8846-3e610998aef7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e04e617",
   "metadata": {},
   "source": [
    "### 14. Have you reviewed the course wiki-textbook and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it?<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    ">  _Here is the link of [wiki-textbook](https://github.com/pointOfive/stat130chat130/wiki) in case it gets lost among all the information you need to keep track of_  : )\n",
    ">\n",
    "> _Just answering \"Yes\" or \"No\" or \"Somewhat\" or \"Mostly\" or whatever here is fine as this question isn't a part of the rubric; but, the midterm and final exams may ask questions that are based on the tutorial and lecture materials; and, your own skills will be limited by your familiarity with these materials (which will determine your ability to actually do actual things effectively with these skills... like the course project...)_\n",
    "</details>    \n",
    "\n",
    "## Recommended Additional Useful Activities [Optional]\n",
    "\n",
    "The \"Ethical Profesionalism Considerations\" and \"Current Course Project Capability Level\" sections below **are not a part of the required homework assignment**; rather, they are regular weekly guides covering (a) relevant considerations regarding professional and ethical conduct, and (b) the analysis steps for the STA130 course project that are feasible at the current stage of the course \n",
    "\n",
    "<br>\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Ethical Professionalism Considerations</u></summary>\n",
    "\n",
    "### Ethical Professionalism Considerations\n",
    "    \n",
    "The TUT and HW both addressed some of the assumptions used in **Simple Linear Regression**. The **p-values** provided by `statsmodels` via `smf.ols(...).fit()` depend on these assumptions, so if they are not (at least approximately) correct, the **p-values** (and any subsequent claims regarding the \"evidience against\" the **null hypothesis**) are not reliable. In light of this consideration, describe how you could diagnostically check the first three assumptions (given below) when using analyses based on **Simple Linear regression** model. From an Ethical and Professional perspective, do you think doing diagnostic checks on the assumptions of a **Simple Linear regression** model is something you can and should do whenever you're doing this kind of analysis? \n",
    "            \n",
    "> The first three assumptions associated with the **Simple Linear regression** model are that\n",
    "> \n",
    "> - the $\\epsilon_i$ **errors** (sometimes referred to as the **noise**) are **normally distributed**\n",
    "> - the $\\epsilon_i$ **errors** are **homoscedastic** (so their distributional variance $\\sigma^2$ does not change as a function of $x_i$)\n",
    "> - the linear form is [at least reasonably approximately] \"true\" (in the sense that the above two remain [at least reasonably approximately] \"true\") so that then behavior of the $Y_i$ **outcomes** are represented/determined on average by the **linear equation**)<br>\n",
    "> \n",
    ">    and there are additional assumptions; but, a deeper reflection on these is \"beyond the scope\" of STA130; nonetheless, they are that<br><br>\n",
    "> - the $x_i$ **predictor variable** is **measured without error**\n",
    "> - and the $\\epsilon_i$ **errors** are **statistically independent** (so their values do not depend on each other)\n",
    "> - and the $\\epsilon_i$ **errors** are **unbiased** relative to the **expected value** of **outcome** $E[Y_i|x_i]=\\beta_0 + \\beta_1x_i$ (which is equivalently stated by saying that the mean of the **error distribution** is $0$, or again equivalently, that the **expected value** of the **errors** $E[\\epsilon_i] = 0$)\n",
    "    \n",
    "</details>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Current Course Project Capability Level</u></summary>\n",
    "\n",
    "**Remember to abide by the [data use agreement](https://static1.squarespace.com/static/60283c2e174c122f8ebe0f39/t/6239c284d610f76fed5a2e69/1647952517436/Data+Use+Agreement+for+the+Canadian+Social+Connection+Survey.pdf) at all times.**\n",
    "\n",
    "Information about the course project is available on the course github repo [here](https://github.com/pointOfive/stat130chat130/tree/main/CP), including a draft [course project specfication](https://github.com/pointOfive/stat130chat130/blob/main/CP/STA130F23_course_project_specification.ipynb) (subject to change). \n",
    "- The Week 01 HW introduced [STA130F24_CourseProject.ipynb](https://github.com/pointOfive/stat130chat130/blob/main/CP/STA130F24_CourseProject.ipynb), and the [available variables](https://drive.google.com/file/d/1ISVymGn-WR1lcRs4psIym2N3or5onNBi/view). \n",
    "- Please do not download the [data](https://drive.google.com/file/d/1mbUQlMTrNYA7Ly5eImVRBn16Ehy9Lggo/view) accessible at the bottom of the [CSCS](https://casch.org/cscs) webpage (or the course github repo) multiple times.\n",
    "    \n",
    "> ### NEW DEVELOPMENT<br>New Abilities Achieved and New Levels Unlocked!!!    \n",
    "> **As noted, the Week 01 HW introduced the [STA130F24_CourseProject.ipynb](https://github.com/pointOfive/stat130chat130/blob/main/CP/STA130F24_CourseProject.ipynb) notebook.** _And there it instructed students to explore the notebook through the first 16 cells of the notebook._ The following cell in that notebook (there marked as \"run cell 17\") is preceded by an introductory section titled, \"**Now for some comparisons...**\", _**and all material from that point on provides an example to allow you to start applying what you're learning about Hypothesis Testing to the CSCS data**_ **using a paired samples (\"one sample\") framework.**\n",
    ">\n",
    "> **NOW, HOWEVER, YOU CAN DO MORE.** \n",
    "> - _**Now you can do \"two sample\" hypothesis testing without the need for paired samples.**_ All you need are two groups.\n",
    "> - _**And now you can do simple linear regression modeling.**_ All you need are two columns.\n",
    "\n",
    "### Current Course Project Capability Level\n",
    "\n",
    "At this point in the course you should be able to do a **Simple Linear Regression** analysis for data from the Canadian Social Connection Survey data\n",
    "    \n",
    "1. Create and test a **null hypothesis** of no linear association \"on average\" for a couple of columns of interest in the Canadian Social Connection Survey data using **Simple Linear Regression**\n",
    "\n",
    "2. Use the **residuals** of a fitted **Simple Linear Regression** model to diagnostically assess some of the assumptions of the analysis\n",
    "\n",
    "3. Use an **indicator variable** based **Simple Linear Regression** model to compare two groups from the Canadian Social Connection Survey data\n",
    "\n",
    "4. Compare and contrast the results of an **indicator variable** based **Simple Linear Regression** model to analyses based on a **permutation test** and a **bootstrapped confidence interval**   \n",
    "    \n",
    "</details>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca1d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
